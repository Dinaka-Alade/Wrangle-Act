{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "822248d2",
   "metadata": {},
   "source": [
    "# Wrangle Report!\n",
    "\n",
    "\n",
    "## We rate dogs!\n",
    "\n",
    "\n",
    "### Introduction\n",
    "The purpose of this project is to put to practices what I've learnt in lesson 3 of udacity data analysis nano degree course (data wrangling). The data set wrangled is twitter-archive-enhanced.csv (we rate dogs). We rate dogs is a twitter account that rate dogs online. This rating usualy have a denominator of 10. This report briefly describe my effort in wrangling the data.\n",
    "\n",
    "\n",
    "\n",
    "### Data wrangling steps\n",
    "- Data gathering\n",
    "- Assessing the data\n",
    "- Cleaning the data\n",
    "\n",
    "\n",
    "### Details of steps taken in wrangling\n",
    "1- Data gathering For this project, 3 datas were required and they were downloaded in different ways\n",
    "\n",
    "- twitter-archive-enhanced.csv : This data was provided by udacity and was downloaded directly from the classroom page\n",
    "- image_predictions.tsv : this file was downloaded programatically using the Requests library. Download link was provided in the classroom page\n",
    "- Twitter api/Json file : using tweets id in twitter-archive-enhanced.csv I queryed each tweet in the api. I couldn't get access to use Twitter's API, so i used the alternative files provided by Udacity\n",
    "\n",
    "\n",
    "2 - Assessing data\n",
    "After gathering the required data, I assesed both visually and programmatically to see the data type in each rows and columns and to know what and how to clean the data. Some functions used during this process are;\n",
    "\n",
    ".head()\n",
    ".info()\n",
    ".shape\n",
    ".dtypes\n",
    ".describe() &\n",
    ".value_counts()\n",
    "\n",
    "\n",
    "3 - Data cleaning\n",
    "After assessing i proceeded to cleaning the data. I made a copy first to preserve the gathered data. Here are the issues i identified during assessment;\n",
    "\n",
    "Quality issues:\n",
    "\n",
    "Twitter_archive\n",
    "\n",
    "- Keep only original ratings that have images.\n",
    "- Delete columns that wonâ€™t be used for the analysis.\n",
    "- Correct numerators (outliers) and convert to float\n",
    "- Convert denominators to float\n",
    "- Correct the incorrect dogs names; Error in dog names (e.g a,an,actually) are not a dog's name.\n",
    "- Erroneous datatypes (Change tweet_id from type interger to object type, change 'timestamp' from object to datetime).\n",
    "\n",
    "Image Predictions\n",
    "\n",
    "- Change tweet_id from type interger to object type\n",
    "- Drop duplicated image predictions\n",
    "\n",
    "Json File\n",
    "- Change 'id' to 'tweet_id'\n",
    "- Erroneous datatypes (Change tweet_id from type interger to object type)\n",
    "\n",
    "Tidiness\n",
    "\n",
    "Twitter Archive\n",
    "\n",
    "- Separate timestamp into day -month -year.\n",
    "- doggo, floofer, pupper and puppo columns in twitter_archive table should be merged into one column named \"dog_stage\"\n",
    "\n",
    "Image Predictions\n",
    "- Merge with Twitter Archive\n",
    "\n",
    "Json File\n",
    "- Merge with Twitter Archive\n",
    "\n",
    "\n",
    "### Limitations\n",
    "I had few challenges while cleaning my data, these challenges include:\n",
    "\n",
    "- Getting a twitter api key\n",
    "I initally didn't understand how to query the json file until it was explained better to me on the slack channel\n",
    "- The rating value in my dataset was missing, I had to analyse without rating which limited my analysis\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "Cleaning data programatically using python is efficient and you can be sure of accuracy. Cleaning manualy takes time and effort. If there was an issue while cleaning, I could easily revert back without loss of data. I also appreciate the packages that has been made available in python to make life easier!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
